{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Text with LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is enabled with initial size: 70.0% of memory, cuDNN 5105)\n",
      "/home/liuweijie/workspace/DeepLearning/deep_learning_with_python/.env/local/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Reshape, LSTM, Dropout, Flatten\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# fix random seed\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "# setting\n",
    "look_back = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepara Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163182\n",
      "57\n",
      "['\\n', ' ', '!', '\"', '$', '%', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '@', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# load text\n",
    "filename = \"./data_set/wonderland.txt\"\n",
    "raw_text = open(filename).read()\n",
    "raw_text = raw_text.lower()\n",
    "print(len(raw_text))\n",
    "\n",
    "# show alphabets\n",
    "chars = sorted(list(set(raw_text)))\n",
    "print len(chars)\n",
    "print chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, '!': 2, ' ': 1, '\"': 3, '%': 5, '$': 4, \"'\": 6, ')': 8, '(': 7, '*': 9, '-': 11, ',': 10, '/': 13, '.': 12, '1': 15, '0': 14, '3': 17, '2': 16, '5': 19, '4': 18, '7': 21, '6': 20, '9': 23, '8': 22, ';': 25, ':': 24, '?': 26, '@': 27, '[': 28, ']': 29, '_': 30, 'a': 31, 'c': 33, 'b': 32, 'e': 35, 'd': 34, 'g': 37, 'f': 36, 'i': 39, 'h': 38, 'k': 41, 'j': 40, 'm': 43, 'l': 42, 'o': 45, 'n': 44, 'q': 47, 'p': 46, 's': 49, 'r': 48, 'u': 51, 't': 50, 'w': 53, 'v': 52, 'y': 55, 'x': 54, 'z': 56}\n"
     ]
    }
   ],
   "source": [
    "# create map of chars to integers\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "print char_to_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataset of input and output from raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163082, 100) (163082,)\n",
      "(163082, 57)\n"
     ]
    }
   ],
   "source": [
    "# create dataset function \n",
    "def create_dataset(sequence, look_back=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(0, len(sequence) - look_back, 1):\n",
    "        X.append(sequence[i: i + look_back])\n",
    "        Y.append(sequence[i + look_back])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "# create dataset\n",
    "int_text = [char_to_int[c] for c in raw_text]\n",
    "X, Y = create_dataset(int_text, look_back)\n",
    "print X.shape, Y.shape\n",
    "\n",
    "# translate Y to one-hot-vercor\n",
    "Y = np_utils.to_categorical(Y)\n",
    "print Y.shape\n",
    "\n",
    "# get some variables we will use\n",
    "len_y_vec = Y.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "reshape_1 (Reshape)              (None, 100, 1)        0           reshape_input_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 100, 256)      264192      reshape_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 25600)         0           lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 57)            1459257     flatten_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1723449\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def create_lstm_model():\n",
    "    model = Sequential()\n",
    "    model.add(Reshape((look_back, 1), input_shape=(look_back, )))\n",
    "    model.add(LSTM(256, return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(len_y_vec, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "lstm = create_lstm_model()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train Model\n",
    "\n",
    "The network is slow to train (about 300 seconds per epoch on an Nvidia K520 GPU). Because of the slowness and because of our optimization requirements, we will use model checkpointing to record all of the network weights to file each time an improvement in loss is observed at the end of the epoch. We will use the best set of weights (lowest loss) to instantiate our generative model in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "163072/163082 [============================>.] - ETA: 0s - loss: 2.9128Epoch 00000: loss improved from inf to 2.91275, saving model to ./models/c28/best_model.hdf5\n",
      "163082/163082 [==============================] - 90s - loss: 2.9127    \n",
      "Epoch 2/2\n",
      "163072/163082 [============================>.] - ETA: 0s - loss: 2.5498Epoch 00001: loss improved from 2.91275 to 2.54976, saving model to ./models/c28/best_model.hdf5\n",
      "163082/163082 [==============================] - 90s - loss: 2.5498    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f28a886e8d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"./models/c28/best_model.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=10, save_best_only=True, mode='min')\n",
    "\n",
    "lstm.fit(X, Y, nb_epoch=2, batch_size=128, callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "reshape_2 (Reshape)              (None, 100, 1)        0           reshape_input_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 100, 256)      264192      reshape_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 25600)         0           lstm_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 57)            1459257     flatten_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1723449\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = create_lstm_model()\n",
    "model.load_weights(filepath)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d', ' ', 't', 'h', 'e', ' ', 'k', 'i', 'n', 'g', '.', '\\n', '\\n', \"'\", 'n', 'e', 'a', 'r', 'l', 'y', ' ', 't', 'w', 'o', ' ', 'm', 'i', 'l', 'e', 's', ' ', 'h', 'i', 'g', 'h', ',', \"'\", ' ', 'a', 'd', 'd', 'e', 'd', ' ', 't', 'h', 'e', ' ', 'q', 'u', 'e', 'e', 'n', '.', '\\n', '\\n', \"'\", 'w', 'e', 'l', 'l', ',', ' ', 'i', ' ', 's', 'h', 'a', 'n', \"'\", 't', ' ', 'g', 'o', ',', ' ', 'a', 't', ' ', 'a', 'n', 'y', ' ', 'r', 'a', 't', 'e', ',', \"'\", ' ', 's', 'a', 'i', 'd', ' ', 'a', 'l', 'i', 'c', 'e']\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = np.random.randint(0, len(X) - 1)\n",
    "start_x = X[start].reshape(look_back, )\n",
    "print [int_to_char[i] for i in start_x]  # change bcak to char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# generate text\n",
    "nb_gen_chars = 1000\n",
    "x = start_x\n",
    "gene_text = ''\n",
    "for i in range(nb_gen_chars):\n",
    "    input_x = x.reshape(1, len(x), )\n",
    "    next_int_vec = model.predict(input_x, verbose=0)\n",
    "    next_int = np.argmax(next_int_vec)\n",
    "    next_char = int_to_char[next_int]\n",
    "    gene_text += next_char\n",
    "    x = np.append(x, next_int)[1: ]\n",
    "print \"\\nDone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "'io whe woet toe toe hiree\n",
      "fo the sort oi ho whe hoot a lart wh toe woe har toe har to the soo ho whe wast th her the to the lart a lart a lote fo the lart a mirg th the lo she hore the tast th her tas oar to the ho the hare a lort so the soet whe hot he a litg th the ho the here whe wart th her to the hart sh the wart a lart th the for th ho the lo the hart a firt fi the woet a mirt th the lo she sor hare to the toe th the lart oi the mart th the hoo ho a lirt oo the lo the hort a sirt th the for th the sart th the hoo th her the har toe tar so the sort a lart th the lort sh the woe ho sh har to the ho the ho the hart a lott ti the foot sar at a lirg to the toe har tar woe to the hor hes toe har th the tart a lint ti the loot a lirt of the lo the hare the sart th her to the hart wh her the har to the woet a lart of the loot a sirt wh ho the har to the hire th the hare th the hor has tart al a lire th the woet as the woet wh ho she ho the sart a lirte sar so the siat a lare th the la\n"
     ]
    }
   ],
   "source": [
    "print gene_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
