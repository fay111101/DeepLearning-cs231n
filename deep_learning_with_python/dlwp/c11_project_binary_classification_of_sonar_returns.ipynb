{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C11: Project: Binary Classification of Sonar Returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download Dataset\n",
    "\n",
    "In terminal\n",
    "\n",
    "```\n",
    "$ cd dlwp/data_set/\n",
    "$ ./get_sonar_data.sh\n",
    "```\n",
    "\n",
    "The data file named \"sonar.data\" will be downloaded to this diercory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the classes and functions we will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read dataset\n",
    "dataframe = pd.read_csv('./data_set/sonar.data', header=None)\n",
    "dataset = dataframe.values\n",
    "X = dataset[:, :60].astype(float)\n",
    "Y = dataset[:, 60]\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "Y_enc = encoder.transform(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline Model\n",
    "\n",
    "Create baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create baseline model\n",
    "def create_baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_dim=60, init='normal', activation='relu'))\n",
    "    model.add(Dense(1, init='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# translate to sklearn form\n",
    "estimator = KerasClassifier(build_fn=create_baseline_model, nb_epoch=100, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Acc: 81.68% (5.67%)\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, Y_enc, cv=kfold)\n",
    "print \"Baseline Acc: %.2f%% (%.2f%%)\"%(results.mean()*100, results.std()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Improve Performance With Data Preprocessing\n",
    "\n",
    "Add a StandardScalar process through pipeline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('standardize', StandardScaler()),\n",
    "    ('mlp', estimator),\n",
    "]\n",
    "pipeline = Pipeline(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with StandardScaler Acc: 82.66% (5.83%)\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_score(pipeline, X, Y_enc, cv=kfold)\n",
    "print \"Model with StandardScaler Acc: %.2f%% (%.2f%%)\"%(results.mean()*100, results.std()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tuning Layers and Neurons in the Model\n",
    "\n",
    "Change the structure of network (called tepology): making it smaller or larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Evaluate a Smaller Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a smaller network\n",
    "def create_smaller_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=60, init='normal', activation='relu'))\n",
    "    model.add(Dense(1, init='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set random seed\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create pipeline model\n",
    "pipeline = [\n",
    "    ('standardize', StandardScaler()),\n",
    "    ('mlp', KerasClassifier(build_fn=create_smaller_model, nb_epoch=100, batch_size=5, verbose=0))\n",
    "]\n",
    "estimator = Pipeline(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smaller Network Acc: 87.00% (4.34%)\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, Y_enc, cv=kfold)\n",
    "print \"Smaller Network Acc: %.2f%% (%.2f%%)\"%(results.mean()*100, results.std()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Much better than before!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Evaluate a Larger Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger Netwotk Acc: 86.47% (3.82%)\n"
     ]
    }
   ],
   "source": [
    "# define a larger network\n",
    "def create_large_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_dim=60, init='normal', activation='relu'))\n",
    "    model.add(Dense(30, init='normal', activation='relu'))\n",
    "    model.add(Dense(1, init='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# set random seed\n",
    "seed = 7\n",
    "np.random.seed(7)\n",
    "\n",
    "# assemble a model\n",
    "pipeline = [\n",
    "    ('standardlze', StandardScaler()),\n",
    "    ('mlp', KerasClassifier(build_fn=create_large_model, nb_epoch=100, batch_size=5, verbose=0))\n",
    "]\n",
    "estimator = Pipeline(pipeline)\n",
    "\n",
    "# evaluate model\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, Y_enc, cv=kfold)\n",
    "print \"Larger Netwotk Acc: %.2f%% (%.2f%%)\"%(results.mean()*100, results.std()*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
