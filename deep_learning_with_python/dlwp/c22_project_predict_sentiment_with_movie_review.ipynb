{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 22: Project: Predict Sentiment From Movie Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "from keras.layers import Embedding\n",
    "\n",
    "# fix random seed\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. IMDB Dataset\n",
    "\n",
    "### What is IMDB Dataset\n",
    "\n",
    "The Large Movie Review Dataset (often referred to as the IMDB dataset) contains 25,000 highly-polar movie reviews (good or bad) for training and the same amount again for testing. The problem is to determine whether a given moving review has a positive or negative sentiment.\n",
    "\n",
    "### Download Dataset\n",
    "\n",
    "Keras offer a API to load IMDB dataset. When the dataset is stored at ~/.keras/datasets/imdb.pkl as a 32M file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) object\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "(X_train, Y_train), (X_val, Y_val) = imdb.load_data(nb_words=5000)\n",
    "print X_train.shape, X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "print type(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Preprocess\n",
    "\n",
    "Bound the length of word sequence to 500, truncating longer reviews and zero-padding shorter reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_val = sequence.pad_sequences(X_val, maxlen=max_words)\n",
    "\n",
    "print len(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build a Simple Model\n",
    "\n",
    "We will use an Embedding layer as the input layer, setting the vocabulary to 5,000, the word vector size to 32 dimensions and the input length to 500. The output of this first layer will be a 32x500 sized matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_3 (Embedding)          (None, 500, 32)       160000      embedding_input_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 16000)         0           embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 250)           4000250     flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 1)             251         dense_5[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 4160501\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define a simple model\n",
    "def create_simple_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(5000, 32, input_length=max_words))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(250, init='normal', activation='relu'))\n",
    "    model.add(Dense(1, init='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "simple_model = create_simple_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 61s - loss: 0.4090 - acc: 0.7919 - val_loss: 0.2966 - val_acc: 0.8722\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 61s - loss: 0.1198 - acc: 0.9563 - val_loss: 0.3784 - val_acc: 0.8578\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 63s - loss: 0.0179 - acc: 0.9950 - val_loss: 0.6110 - val_acc: 0.8537\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 62s - loss: 0.0033 - acc: 0.9992 - val_loss: 0.7566 - val_acc: 0.8514\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 62s - loss: 0.0116 - acc: 0.9962 - val_loss: 0.7755 - val_acc: 0.8372\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 62s - loss: 0.0319 - acc: 0.9888 - val_loss: 0.6315 - val_acc: 0.8499\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 65s - loss: 0.0075 - acc: 0.9978 - val_loss: 0.9170 - val_acc: 0.8482\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 65s - loss: 0.0030 - acc: 0.9991 - val_loss: 1.0125 - val_acc: 0.8503\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 63s - loss: 0.0029 - acc: 0.9990 - val_loss: 1.0858 - val_acc: 0.8450\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 66s - loss: 0.0132 - acc: 0.9956 - val_loss: 0.9338 - val_acc: 0.8426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1230fcd10>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.fit(X_train, Y_train, validation_data=(X_val, Y_val), nb_epoch=10, batch_size=30, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build 1-D Conv Layer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_7 (Embedding)          (None, 500, 32)       160000      embedding_input_7[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution1d_1 (Convolution1D)  (None, 500, 32)       3104        embedding_7[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling1d_1 (MaxPooling1D)    (None, 250, 32)       0           convolution1d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 8000)          0           maxpooling1d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 250)           2000250     flatten_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 1)             251         dense_7[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 2163605\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define conv model\n",
    "def create_conv_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(5000, 32, input_length=max_words))\n",
    "    model.add(Convolution1D(nb_filter=32, filter_length=3, border_mode='same', activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_length=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "conv_model = create_conv_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 99s - loss: 0.3745 - acc: 0.8087 - val_loss: 0.2653 - val_acc: 0.8894\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 141s - loss: 0.2033 - acc: 0.9209 - val_loss: 0.2939 - val_acc: 0.8806\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 139s - loss: 0.1373 - acc: 0.9496 - val_loss: 0.3168 - val_acc: 0.8816\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 141s - loss: 0.0798 - acc: 0.9726 - val_loss: 0.4290 - val_acc: 0.8744\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 132s - loss: 0.0401 - acc: 0.9874 - val_loss: 0.5635 - val_acc: 0.8716\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 133s - loss: 0.0278 - acc: 0.9903 - val_loss: 0.6123 - val_acc: 0.8680\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 128s - loss: 0.0234 - acc: 0.9920 - val_loss: 0.6532 - val_acc: 0.8669\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 123s - loss: 0.0198 - acc: 0.9930 - val_loss: 0.7127 - val_acc: 0.8634\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 121s - loss: 0.0134 - acc: 0.9955 - val_loss: 0.8337 - val_acc: 0.8677\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 126s - loss: 0.0094 - acc: 0.9967 - val_loss: 0.9179 - val_acc: 0.8625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10e6cab10>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model.fit(X_train, Y_train, validation_data=(X_val, Y_val), nb_epoch=10, batch_size=30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
